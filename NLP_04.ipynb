{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de3b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b683bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math\n",
    "from torch.autograd import Function\n",
    "class MyMul(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, y):\n",
    "        ctx.save_for_backward(x,y)\n",
    "        return x * y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x,y = ctx.saved_tensors\n",
    "        return grad_output * y,grad_output * x\n",
    "\n",
    "class MyMax(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, y):\n",
    "        ctx.save_for_backward(x,y)\n",
    "        return torch.maximum(x,y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x,y  = ctx.saved_tensors\n",
    "        \n",
    "        maskx = x > y\n",
    "        masky = x < y\n",
    "        maskequal = x == y \n",
    "\n",
    "        grad_x = torch.where(maskx, grad_output, torch.where(maskequal, grad_output * 0.5, torch.zeros_like(grad_output)))\n",
    "        grad_y = torch.where(masky, grad_output, torch.where(maskequal, grad_output * 0.5, torch.zeros_like(grad_output)))\n",
    "        \n",
    "        return grad_x, grad_y \n",
    "\n",
    "class MyCos(Function):\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x) \n",
    "        return torch.cos(x)\n",
    "    def backward(ctx, gradient_output):\n",
    "        x, = ctx.saved_tensors\n",
    "        grad_input = gradient_output * -torch.sin(x)\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "780faad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import gradcheck\n",
    "\n",
    "x = torch.randn(3, dtype=torch.double, requires_grad=True)\n",
    "y = torch.randn(3, dtype=torch.double, requires_grad=True)\n",
    "\n",
    "# Make sure inputs are a tuple of tensors\n",
    "inputs = (x, y)\n",
    "\n",
    "# Run gradcheck\n",
    "print(gradcheck(MyMul.apply, inputs))\n",
    "print(gradcheck(MyMax.apply, inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "072e956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math \n",
    "import torch.nn.functional \n",
    "\n",
    "class CosLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias):\n",
    "        super().__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.reset_parameters()\n",
    "        if bias: \n",
    "            self.bias = torch.nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "   \n",
    "        torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5)) # Kaiming uniform initialization to avoid vanishing or exploding gradients \n",
    "\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) # shrinks initial weight valeus for many inputs \n",
    "            torch.nn.init.uniform_(self.bias, -bound, bound) # initializes bias with random values in range of -bound to bound \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        weight_with_cos = MyCos.apply(self.weight)\n",
    "        return torch.nn.functional.linear(input, weight_with_cos, self.bias)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c0e2f",
   "metadata": {},
   "source": [
    "# Dynamic Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc082c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(64,32)\n",
    "        self.hidden_layer = nn.Linear(32,32)\n",
    "        self.output_layer = nn.Linear(32,1)\n",
    "\n",
    "\n",
    "    def forward(self,input):\n",
    "        \n",
    "        outputs = []\n",
    "        if self.training:\n",
    "            x1 = F.relu(self.linear(input))\n",
    "            num_layers = torch.randint(1,5,(1,)).item()\n",
    "            for _ in range(num_layers): #apply hidden layer multiple times for non linearity\n",
    "                x1 = F.relu(self.hidden_layer(x1))   \n",
    "            return self.output_layer(x1)\n",
    "                \n",
    "\n",
    "        else:\n",
    "            for n in range(1,5):\n",
    "                x = F.relu(self.linear(input))\n",
    "                for _ in range(n):\n",
    "                    x = F.relu(self.hidden_layer(x))\n",
    "                out = self.output_layer(x)\n",
    "                outputs.append(out)\n",
    "        \n",
    "        mean_outputs = torch.stack(outputs).mean(dim=0)\n",
    "\n",
    "        return mean_outputs      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e318a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 2**14\n",
    "dim_input = 64\n",
    "dim_output = 1\n",
    "\n",
    "X = np.random.randn(n, dim_input).astype(np.float32)\n",
    "\n",
    "true_weights = np.random.randn(dim_input, dim_output)\n",
    "y = X @ true_weights + np.random.randn(n, dim_output) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45c38884",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.random.permutation(n)\n",
    "split = int(n * 0.75)\n",
    "\n",
    "train = samples[:split]\n",
    "test = samples[split:]\n",
    "\n",
    "X_train, y_train = X[train], y[train]\n",
    "X_test, y_test = X[test], y[test]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
